# E-commerce Demand Forecasting with 3D Analytics

[![pt-br](https://img.shields.io/badge/ğŸ‡§ğŸ‡·_Ler_em_PortuguÃªs-Clique_Aqui-green?style=for-the-badge)](#pt-br)

> **Status:** Planning / early development ğŸš§

Forecasting e-commerce demand per category/SKU using real-world-like data, with a focus on **EDA**, **time-series models**, **3D visualizations** and an **interactive BI dashboard**.

---

## ğŸ“Œ Project Overview

**Goal**
Analyze e-commerce sales data to understand **purchase patterns** and build a **demand forecasting model** (per category/SKU) with proper **backtesting** and **business-oriented metrics**.

**Key outputs**

- Clean and well-documented dataset (`data/raw`, `data/processed`)
- EDA with 2D and 3D visualizations (Plotly)
- Time-series forecasting models with rolling-origin backtesting
- Interactive dashboard (Power BI / Plotly) with a **price & promotion simulator**

---

## ğŸ“Š Dataset

_To be defined._

Planned options:

- Public e-commerce datasets from Kaggle (e.g. Brazilian e-commerce data)
- Synthetic dataset generated to simulate categories/SKUs, price and promotions

Once defined, this section will include:

- Link to the original source
- Data dictionary (main columns)
- Basic notes about preprocessing and limitations

---

## ğŸ—‚ Repository Structure

Current structure (will evolve as the project grows):

    .
    â”œâ”€â”€ data
    â”‚   â”œâ”€â”€ raw/                           # Original datasets (not tracked in Git)
    â”‚   â””â”€â”€ processed/                     # Cleaned / transformed data (not tracked in Git)
    â”œâ”€â”€ notebooks
    â”‚   â”œâ”€â”€ 00_smoke_tests.ipynb           # Environment / smoke tests
    â”‚   â””â”€â”€ 01_data_overview_and_eda.ipynb # Initial data overview and EDA
    â”œâ”€â”€ scripts
    â”‚   â””â”€â”€ run_all.py                     # Stub to run the full pipeline (to be implemented)
    â”œâ”€â”€ src
    â”‚   â”œâ”€â”€ data/
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”œâ”€â”€ config.py                  # Central config (paths, constants, etc.)
    â”‚   â”‚   â”œâ”€â”€ load.py                    # Data loading helpers
    â”‚   â”‚   â””â”€â”€ preprocess.py              # Cleaning & feature engineering helpers
    â”‚   â””â”€â”€ _template/
    â”‚       â””â”€â”€ script_template.py         # Template for new Python scripts
    â”œâ”€â”€ reports/                           # Analysis outputs (figures, exports)
    â”œâ”€â”€ dashboard/                         # BI / dashboard files (Power BI / Plotly)
    â”œâ”€â”€ .env.example                       # Example environment variables (copy to .env)
    â”œâ”€â”€ requirements.txt                   # Main project dependencies
    â”œâ”€â”€ requirements-dev.txt               # Dev tools (pre-commit, black, isort)
    â””â”€â”€ README.md

> Additional notebooks and modules will be added as the project evolves
> (e.g. `notebooks/02_modeling_forecast.ipynb`, extra model/evaluation utilities, etc.).

---

## ğŸ§° Tech Stack

- **Python** (Pandas, NumPy, Scikit-learn, Statsmodels, Plotly)
- **Time-series & forecasting** (baseline models, optionally LightGBM/XGBoost/Prophet)
- **Jupyter Notebook**
- **Power BI / Plotly** for dashboards
- **Git & GitHub** for version control
- **pre-commit, black, isort** for code quality

---

## ğŸ” Work Plan

1. **Data Collection & Preparation**
   - Select a public e-commerce dataset
   - Save raw data in `data/raw/`
   - Build a simple data dictionary and initial checks
2. **Cleaning & Feature Engineering**
   - Handle missing values and outliers
   - Create calendar features (weekday, month, holidays)
   - Create lags and moving averages (e.g. `sales_t-1`, `sales_t-7`)
   - Aggregate at the chosen grain (category and/or SKU)
3. **EDA & 3D Visualizations**
   - Explore seasonality and trends by category
   - Correlation analysis (price, discount, sales, lags)
   - 3D scatter/line plots (price Ã— sales Ã— discount, color = category)
4. **Forecasting Models & Backtesting**
   - Baselines: Naive, Seasonal Naive, Moving Average
   - Models: ElasticNet / Gradient Boosting / LightGBM or similar
   - Rolling-origin backtesting with MAE and wMAPE
   - Error analysis by category and by time window
5. **Dashboard & Simulator**
   - Build an interactive dashboard (Power BI / Plotly)
   - Price/promotion sliders and comparison vs current scenario
   - Highlight main insights and recommendations
6. **Documentation**
   - Document how to run the project and main insights
   - Add plots and dashboard screenshots to the README
   - Save metrics and backtesting results in structured files (e.g. `metrics.json`)

---

## ğŸš€ How to Run (work in progress)

1. **Clone this repository**

       git clone https://github.com/LucasFDL/ecommerce-demand-forecasting-3d-analytics.git
       cd ecommerce-demand-forecasting-3d-analytics

2. **Create a virtual environment**

       python -m venv .venv

3. **Activate the virtual environment**

   **On Windows:**

       .\.venv\Scripts\activate

   **On Linux/macOS:**

       source .venv/bin/activate

4. **Install dependencies**

       pip install -r requirements.txt
       pip install -r requirements-dev.txt    # optional (dev tools)
       pre-commit install                     # set up Git hooks

5. **(Optional) Configure environment variables**

       # Copy .env.example to .env (via Explorer or command line)
       # and edit .env with the required values

6. **Open the notebooks**

       jupyter notebook

> This section will be updated as the project evolves (specific commands, scripts, and environment details).

---

## âœ… Status & Next Steps

- [x] Create repository and initial README
- [x] Set up `requirements.txt` and initial folder structure
- [ ] Choose dataset and describe it in the **Dataset** section
- [ ] Implement and document EDA (`notebooks/01_data_overview_and_eda.ipynb`)
- [ ] Implement forecasting models and backtesting (`notebooks/02_modeling_forecast.ipynb`)
- [ ] Build dashboard and add screenshots to `reports/` and this README

---

## ğŸ“¬ Contact

Suggestions, ideas or feedback are welcome:
  - GitHub: @LucasFDL
  - LinkedIn: Lucas Dias
  - Email: lucasdias000722@gmail.com

<br>
<br>

---

<a name="pt-br"></a>

<details>
<summary><strong>ğŸ‡§ğŸ‡· Clique aqui para ver a versÃ£o em PortuguÃªs / Click to read in Portuguese</strong></summary>

<br>

# PrevisÃ£o de Demanda E-commerce com Analytics 3D

> **Status:** Planejamento / desenvolvimento inicial ğŸš§

PrevisÃ£o de demanda de e-commerce por categoria/SKU utilizando dados realistas, com foco em **EDA**, **modelos de sÃ©ries temporais**, **visualizaÃ§Ãµes 3D** e um **dashboard de BI interativo**.

---

## ğŸ“Œ VisÃ£o Geral do Projeto

**Objetivo**
Analisar dados de vendas de e-commerce para entender **padrÃµes de compra** e construir um **modelo de previsÃ£o de demanda** (por categoria/SKU) com **backtesting** adequado e **mÃ©tricas orientadas a negÃ³cios**.

**Principais entregas**

- Dataset limpo e bem documentado (`data/raw`, `data/processed`)
- EDA com visualizaÃ§Ãµes 2D e 3D (Plotly)
- Modelos de previsÃ£o de sÃ©ries temporais com backtesting de origem rolante (*rolling-origin*)
- Dashboard interativo (Power BI / Plotly) com um **simulador de preÃ§os e promoÃ§Ãµes**

---

## ğŸ“Š Dataset

_A definir._

OpÃ§Ãµes planejadas:

- Datasets pÃºblicos de e-commerce do Kaggle (ex: dados de e-commerce brasileiro)
- Dataset sintÃ©tico gerado para simular categorias/SKUs, preÃ§os e promoÃ§Ãµes

Assim que definido, esta seÃ§Ã£o incluirÃ¡:

- Link para a fonte original
- DicionÃ¡rio de dados (colunas principais)
- Notas bÃ¡sicas sobre prÃ©-processamento e limitaÃ§Ãµes

---

## ğŸ—‚ Estrutura do RepositÃ³rio

Estrutura atual (pode evoluir conforme o projeto cresce):

    .
    â”œâ”€â”€ data
    â”‚   â”œâ”€â”€ raw/                           # Datasets originais (nÃ£o rastreados no Git)
    â”‚   â””â”€â”€ processed/                     # Dados limpos / transformados (nÃ£o rastreados no Git)
    â”œâ”€â”€ notebooks
    â”‚   â”œâ”€â”€ 00_smoke_tests.ipynb           # Testes de ambiente / fumaÃ§a
    â”‚   â””â”€â”€ 01_data_overview_and_eda.ipynb # VisÃ£o geral inicial dos dados e EDA
    â”œâ”€â”€ scripts
    â”‚   â””â”€â”€ run_all.py                     # Stub para rodar o pipeline completo (a ser implementado)
    â”œâ”€â”€ src
    â”‚   â”œâ”€â”€ data/
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”œâ”€â”€ config.py                  # ConfiguraÃ§Ã£o central (paths, constantes, etc.)
    â”‚   â”‚   â”œâ”€â”€ load.py                    # FunÃ§Ãµes de carregamento de dados
    â”‚   â”‚   â””â”€â”€ preprocess.py              # FunÃ§Ãµes de limpeza e feature engineering
    â”‚   â””â”€â”€ _template/
    â”‚       â””â”€â”€ script_template.py         # Template para novos scripts Python
    â”œâ”€â”€ reports/                           # SaÃ­das de anÃ¡lises (grÃ¡ficos, exports)
    â”œâ”€â”€ dashboard/                         # Arquivos do dashboard (Power BI / Plotly)
    â”œâ”€â”€ .env.example                       # Exemplo de variÃ¡veis de ambiente (copiar para .env)
    â”œâ”€â”€ requirements.txt                   # DependÃªncias principais do projeto
    â”œâ”€â”€ requirements-dev.txt               # Ferramentas de desenvolvimento (pre-commit, black, isort)
    â””â”€â”€ README.md

> Novos notebooks e mÃ³dulos serÃ£o adicionados conforme o projeto evolui
> (por exemplo, `notebooks/02_modeling_forecast.ipynb`, utilitÃ¡rios extras de modelagem/avaliaÃ§Ã£o etc.).

---

## ğŸ§° Tecnologias Utilizadas

- **Python** (Pandas, NumPy, Scikit-learn, Statsmodels, Plotly)
- **SÃ©ries temporais e previsÃ£o** (modelos base, opcionalmente LightGBM/XGBoost/Prophet)
- **Jupyter Notebook**
- **Power BI / Plotly** para dashboards
- **Git & GitHub** para controle de versÃ£o
- **pre-commit, black, isort** para qualidade de cÃ³digo

---

## ğŸ” Plano de Trabalho

1. **Coleta e PreparaÃ§Ã£o de Dados**
   - Selecionar um dataset pÃºblico de e-commerce
   - Salvar dados brutos em `data/raw/`
   - Criar dicionÃ¡rio de dados simples e verificaÃ§Ãµes iniciais
2. **Limpeza e Engenharia de Atributos (Feature Engineering)**
   - Tratar valores ausentes e outliers
   - Criar atributos de calendÃ¡rio (dia da semana, mÃªs, feriados)
   - Criar defasagens (lags) e mÃ©dias mÃ³veis (ex: `vendas_t-1`, `vendas_t-7`)
   - Agregar no nÃ­vel escolhido (categoria e/ou SKU)
3. **EDA e VisualizaÃ§Ãµes 3D**
   - Explorar sazonalidade e tendÃªncias por categoria
   - AnÃ¡lise de correlaÃ§Ã£o (preÃ§o, desconto, vendas, lags)
   - GrÃ¡ficos de dispersÃ£o/linha 3D (preÃ§o Ã— vendas Ã— desconto, cor = categoria)
4. **Modelos de PrevisÃ£o e Backtesting**
   - Baselines: Naive, Sazonal Naive, MÃ©dia MÃ³vel
   - Modelos: ElasticNet / Gradient Boosting / LightGBM ou similar
   - Backtesting de origem rolante com MAE e wMAPE
   - AnÃ¡lise de erro por categoria e por janela de tempo
5. **Dashboard e Simulador**
   - Construir dashboard interativo (Power BI / Plotly)
   - Sliders de preÃ§o/promoÃ§Ã£o e comparaÃ§Ã£o vs cenÃ¡rio atual
   - Destacar principais insights e recomendaÃ§Ãµes
6. **DocumentaÃ§Ã£o**
   - Documentar como rodar o projeto e principais insights
   - Adicionar grÃ¡ficos e screenshots do dashboard ao README
   - Salvar mÃ©tricas e resultados de backtesting em arquivos estruturados (ex: `metrics.json`)

---

## ğŸš€ Como Executar (em andamento)

1. **Clonar este repositÃ³rio**

       git clone https://github.com/LucasFDL/ecommerce-demand-forecasting-3d-analytics.git
       cd ecommerce-demand-forecasting-3d-analytics

2. **Criar um ambiente virtual**

       python -m venv .venv

3. **Ativar o ambiente virtual**

   **No Windows:**

       .\.venv\Scripts\activate

   **No Linux/macOS:**

       source .venv/bin/activate

4. **Instalar dependÃªncias**

       pip install -r requirements.txt
       pip install -r requirements-dev.txt   # opcional (ferramentas de desenvolvimento)
       pre-commit install                    # configurar hooks do Git

5. **(Opcional) Configurar variÃ¡veis de ambiente**

       # Copiar .env.example para .env (pode ser pelo Explorer ou linha de comando)
       # e depois editar o arquivo .env com os valores necessÃ¡rios

6. **Abrir os notebooks**

       jupyter notebook

> Esta seÃ§Ã£o serÃ¡ atualizada conforme o projeto evolui (comandos especÃ­ficos, scripts e detalhes do ambiente).

---

## âœ… Status e PrÃ³ximos Passos

- [x] Criar repositÃ³rio e README inicial
- [x] Configurar `requirements.txt` e estrutura inicial de pastas
- [ ] Escolher dataset e descrevÃª-lo na seÃ§Ã£o **Dataset**
- [ ] Implementar e documentar EDA (`notebooks/01_data_overview_and_eda.ipynb`)
- [ ] Implementar modelos de previsÃ£o e backtesting (`notebooks/02_modeling_forecast.ipynb`)
- [ ] Construir dashboard e adicionar screenshots em `reports/` e neste README

---

## ğŸ“¬ Contato

SugestÃµes, ideias ou feedbacks sÃ£o bem-vindos:
  - GitHub: @LucasFDL
  - LinkedIn: Lucas Dias
  - Email: lucasdias000722@gmail.com

</details>
